{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNys1L7ieFDLgPralnmmv76"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Q1. What is Bayes' Theorem?\n","Bayes' Theorem is a principle in probability theory that describes how to update the probability of a hypothesis based on new evidence. It provides a way to compute the conditional probability of an event given prior knowledge of conditions that might be related to the event.\n","\n","Q2. What is the Formula for Bayes' Theorem?\n","The formula for Bayes' Theorem is:\n","\n","𝑃\n","(\n","𝐴\n","∣\n","𝐵\n",")\n","=\n","𝑃\n","(\n","𝐵\n","∣\n","𝐴\n",")\n","⋅\n","𝑃\n","(\n","𝐴\n",")\n","𝑃\n","(\n","𝐵\n",")\n","P(A∣B)=\n","P(B)\n","P(B∣A)⋅P(A)\n","​\n","\n","\n","Where:\n","\n","𝑃\n","(\n","𝐴\n","∣\n","𝐵\n",")\n","P(A∣B) is the posterior probability of event\n","𝐴\n","A given event\n","𝐵\n","B.\n","𝑃\n","(\n","𝐵\n","∣\n","𝐴\n",")\n","P(B∣A) is the likelihood of event\n","𝐵\n","B given event\n","𝐴\n","A.\n","𝑃\n","(\n","𝐴\n",")\n","P(A) is the prior probability of event\n","𝐴\n","A.\n","𝑃\n","(\n","𝐵\n",")\n","P(B) is the marginal probability of event\n","𝐵\n","B.\n","Q3. How is Bayes' Theorem Used in Practice?\n","Bayes' Theorem is used in various applications, including:\n","\n","Medical Diagnosis: To update the probability of a disease given test results.\n","Spam Filtering: To classify emails as spam or not spam based on features like the presence of certain words.\n","Predictive Analytics: In machine learning models like Naive Bayes classifiers to predict categories based on feature probabilities.\n","Q4. Relationship Between Bayes' Theorem and Conditional Probability\n","Bayes' Theorem is fundamentally about conditional probability. It allows us to reverse conditional probabilities—i.e., compute\n","𝑃\n","(\n","𝐴\n","∣\n","𝐵\n",")\n","P(A∣B) when we know\n","𝑃\n","(\n","𝐵\n","∣\n","𝐴\n",")\n","P(B∣A), using prior probabilities\n","𝑃\n","(\n","𝐴\n",")\n","P(A) and\n","𝑃\n","(\n","𝐵\n",")\n","P(B). Conditional probability\n","𝑃\n","(\n","𝐴\n","∣\n","𝐵\n",")\n","P(A∣B) is the probability of\n","𝐴\n","A given\n","𝐵\n","B, and Bayes' Theorem helps in calculating this by incorporating the likelihood\n","𝑃\n","(\n","𝐵\n","∣\n","𝐴\n",")\n","P(B∣A) and prior probabilities.\n","\n","Q5. Choosing the Type of Naive Bayes Classifier\n","There are several types of Naive Bayes classifiers, each suited for different types of data:\n","\n","Gaussian Naive Bayes: Used when features are continuous and assumed to follow a Gaussian (normal) distribution.\n","Multinomial Naive Bayes: Ideal for discrete features, often used with text classification where feature values are word counts or frequencies.\n","Bernoulli Naive Bayes: Suitable for binary/boolean features where the presence or absence of a feature is important.\n","To choose the right classifier, consider the nature of your features (continuous vs. discrete) and their distribution.\n","\n","Q6. Assignment: Naive Bayes Classification\n","Given the table of feature frequencies:\n","\n","Class\tX1=1\tX1=2\tX1=3\tX2=1\tX2=2\tX2=3\tX2=4\n","A\t3\t3\t4\t4\t3\t3\t3\n","B\t2\t2\t1\t2\t2\t2\t3\n","Calculate the likelihoods for each class:\n","\n","For class\n","𝐴\n","A:\n","\n","𝑃\n","(\n","𝑋\n","1\n","=\n","3\n","∣\n","𝐴\n",")\n","=\n","4\n","3\n","+\n","3\n","+\n","4\n","=\n","4\n","10\n","P(X1=3∣A)=\n","3+3+4\n","4\n","​\n"," =\n","10\n","4\n","​\n","\n","𝑃\n","(\n","𝑋\n","2\n","=\n","4\n","∣\n","𝐴\n",")\n","=\n","3\n","4\n","+\n","3\n","+\n","3\n","+\n","3\n","=\n","3\n","13\n","P(X2=4∣A)=\n","4+3+3+3\n","3\n","​\n"," =\n","13\n","3\n","​\n","\n","For class\n","𝐵\n","B:\n","\n","𝑃\n","(\n","𝑋\n","1\n","=\n","3\n","∣\n","𝐵\n",")\n","=\n","1\n","2\n","+\n","2\n","+\n","1\n","=\n","1\n","5\n","P(X1=3∣B)=\n","2+2+1\n","1\n","​\n"," =\n","5\n","1\n","​\n","\n","𝑃\n","(\n","𝑋\n","2\n","=\n","4\n","∣\n","𝐵\n",")\n","=\n","3\n","2\n","+\n","2\n","+\n","2\n","+\n","3\n","=\n","3\n","9\n","P(X2=4∣B)=\n","2+2+2+3\n","3\n","​\n"," =\n","9\n","3\n","​\n","\n","Compute the posterior probabilities:\n","\n","Since prior probabilities are equal:\n","\n","For class\n","𝐴\n","A:\n","𝑃\n","(\n","𝐴\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n","∝\n","𝑃\n","(\n","𝑋\n","1\n","=\n","3\n","∣\n","𝐴\n",")\n","⋅\n","𝑃\n","(\n","𝑋\n","2\n","=\n","4\n","∣\n","𝐴\n",")\n","P(A∣X1=3,X2=4)∝P(X1=3∣A)⋅P(X2=4∣A)\n","𝑃\n","(\n","𝐴\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n","∝\n","4\n","10\n","⋅\n","3\n","13\n","≈\n","0.0923\n","P(A∣X1=3,X2=4)∝\n","10\n","4\n","​\n"," ⋅\n","13\n","3\n","​\n"," ≈0.0923\n","\n","For class\n","𝐵\n","B:\n","𝑃\n","(\n","𝐵\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n","∝\n","𝑃\n","(\n","𝑋\n","1\n","=\n","3\n","∣\n","𝐵\n",")\n","⋅\n","𝑃\n","(\n","𝑋\n","2\n","=\n","4\n","∣\n","𝐵\n",")\n","P(B∣X1=3,X2=4)∝P(X1=3∣B)⋅P(X2=4∣B)\n","𝑃\n","(\n","𝐵\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n","∝\n","1\n","5\n","⋅\n","3\n","9\n","≈\n","0.0667\n","P(B∣X1=3,X2=4)∝\n","5\n","1\n","​\n"," ⋅\n","9\n","3\n","​\n"," ≈0.0667\n","\n","Predict the class with the highest posterior probability:\n","\n","Since\n","𝑃\n","(\n","𝐴\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n",">\n","𝑃\n","(\n","𝐵\n","∣\n","𝑋\n","1\n","=\n","3\n",",\n","𝑋\n","2\n","=\n","4\n",")\n","P(A∣X1=3,X2=4)>P(B∣X1=3,X2=4), the Naive Bayes classifier would predict class\n","𝐴\n","A for the new instance with\n","𝑋\n","1\n","=\n","3\n","X1=3 and\n","𝑋\n","2\n","=\n","4\n","X2=4."],"metadata":{"id":"YUIRA3Fxf5uQ"}},{"cell_type":"code","source":[],"metadata":{"id":"IiSjw7rvf9AY"},"execution_count":null,"outputs":[]}]}